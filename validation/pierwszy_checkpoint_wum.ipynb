{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc5531a",
   "metadata": {},
   "source": [
    "# Pierwszy checkpoint 1. Projektu z przedmiotu WUM #\n",
    "\n",
    "## Alicja Charuza, Mateusz Gałęziewski #\n",
    "\n",
    "Zbiorem danych, na jakim pracujemy przy naszym projekcie jest [Fake News Dataset](https://www.kaggle.com/datasets/mohammadaflahkhan/fake-news-dataset-combined-different-sources). Poniżej przedstawiamy wyniki naszej pracy przy preprocessingu.\n",
    "\n",
    "Najpierw może zobaczmy, jak wyglądają nasze dane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5c697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4be708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>Ground Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ann Coulter Make Believes She Has ‘Gay Friend...</td>\n",
       "      <td>It s hard to believe, but Donald Trump does ha...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Rating: Moody‘s verbessert Ausblick für Russla...</td>\n",
       "      <td>bankensektor Der russische Staat werde die Ban...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CAN WE ADD DIRTY MONEY ‘LAUNDERING’ To The Oba...</td>\n",
       "      <td>A member of the House Intelligence Committee i...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Republicans on Obamacare repeal: 'We're going ...</td>\n",
       "      <td>WASHINGTON (Reuters) - House of Representative...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Trump, on possible DACA deal, says border wall...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69040</th>\n",
       "      <td>69040</td>\n",
       "      <td>Burundi opposition platform boycotts new round...</td>\n",
       "      <td>NAIROBI (Reuters) - Burundi s main opposition ...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69041</th>\n",
       "      <td>69041</td>\n",
       "      <td>Hillary’s Message To Former Miss Universe Cal...</td>\n",
       "      <td>Miss Universe 1996 Alicia Machado is now an Am...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69042</th>\n",
       "      <td>69042</td>\n",
       "      <td>Cop Crashes Car And Runs Away When More Cops A...</td>\n",
       "      <td>The Daily Sheeple – by Ryan Banister \\r\\nAn aw...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69043</th>\n",
       "      <td>69043</td>\n",
       "      <td>Trump Stole An Idea From North Korean Propaga...</td>\n",
       "      <td>Jesus f*cking Christ our President* is a moron...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69044</th>\n",
       "      <td>69044</td>\n",
       "      <td>BREAKING: HILLARY CLINTON’S STATE DEPARTMENT G...</td>\n",
       "      <td>IF SHE S NOT TOAST NOW THEN WE RE IN BIGGER TR...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69045 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              title  \\\n",
       "0               0   Ann Coulter Make Believes She Has ‘Gay Friend...   \n",
       "1               1  Rating: Moody‘s verbessert Ausblick für Russla...   \n",
       "2               2  CAN WE ADD DIRTY MONEY ‘LAUNDERING’ To The Oba...   \n",
       "3               3  Republicans on Obamacare repeal: 'We're going ...   \n",
       "4               4  Trump, on possible DACA deal, says border wall...   \n",
       "...           ...                                                ...   \n",
       "69040       69040  Burundi opposition platform boycotts new round...   \n",
       "69041       69041   Hillary’s Message To Former Miss Universe Cal...   \n",
       "69042       69042  Cop Crashes Car And Runs Away When More Cops A...   \n",
       "69043       69043   Trump Stole An Idea From North Korean Propaga...   \n",
       "69044       69044  BREAKING: HILLARY CLINTON’S STATE DEPARTMENT G...   \n",
       "\n",
       "                                                    text Ground Label  \n",
       "0      It s hard to believe, but Donald Trump does ha...         fake  \n",
       "1      bankensektor Der russische Staat werde die Ban...         fake  \n",
       "2      A member of the House Intelligence Committee i...         fake  \n",
       "3      WASHINGTON (Reuters) - House of Representative...         true  \n",
       "4      WASHINGTON (Reuters) - U.S. President Donald T...         true  \n",
       "...                                                  ...          ...  \n",
       "69040  NAIROBI (Reuters) - Burundi s main opposition ...         true  \n",
       "69041  Miss Universe 1996 Alicia Machado is now an Am...         fake  \n",
       "69042  The Daily Sheeple – by Ryan Banister \\r\\nAn aw...         fake  \n",
       "69043  Jesus f*cking Christ our President* is a moron...         fake  \n",
       "69044  IF SHE S NOT TOAST NOW THEN WE RE IN BIGGER TR...         fake  \n",
       "\n",
       "[69045 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('original_data.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2c398",
   "metadata": {},
   "source": [
    "Nasza ramka danych zawiera dwie kolumny cech **title** i **text** oraz kolumnę **Ground Label** informującą nas, czy jest to fake news, czy też nie.\n",
    "\n",
    "Pierwszą rzeczą, jaką zrobiliśmy było usunięcie newsów w języku innym niż angielski. Z naszych obserwacji zbioru danych wynika, że były one niemal wszystkie fałszywe, dlatego zdecydowaliśmy się z nich zrezygnować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e94a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def det_lang(df):\n",
    "    def detect_language(text):\n",
    "        try:\n",
    "            lan = detect(text)\n",
    "        except:\n",
    "            lan = 'unknown'\n",
    "        return lan\n",
    "\n",
    "    df['language'] = df['text'].apply(detect_language)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b597c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language  Ground Label\n",
      "af        fake                3\n",
      "ar        fake               22\n",
      "ca        fake                3\n",
      "cy        fake                3\n",
      "da        fake                2\n",
      "de        fake              135\n",
      "el        fake                4\n",
      "en        fake            40539\n",
      "          true            26881\n",
      "es        fake              178\n",
      "et        fake                1\n",
      "fi        fake                2\n",
      "fr        fake               53\n",
      "hr        fake                5\n",
      "hu        fake                1\n",
      "id        fake                1\n",
      "it        fake               11\n",
      "lt        fake                1\n",
      "nl        fake                4\n",
      "no        fake                3\n",
      "pl        fake                4\n",
      "pt        fake               15\n",
      "ro        fake                5\n",
      "ru        fake              203\n",
      "sl        fake                1\n",
      "so        fake                6\n",
      "sv        fake                1\n",
      "sw        fake               13\n",
      "tl        fake                2\n",
      "tr        fake               10\n",
      "unknown   fake              925\n",
      "          true                5\n",
      "vi        fake                2\n",
      "zh-cn     fake                1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_lang = det_lang(df1)\n",
    "counts = df_lang.groupby(['language', 'Ground Label']).size()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b075f7",
   "metadata": {},
   "source": [
    "Oprócz tego usunęliśmy wiersze, które miały puste wartości w obu kolumnach lub też miały mniej niż 30 znaków, gdyż czasami w kolumnie **text** znajdowały się na przykład linki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf006f9",
   "metadata": {},
   "source": [
    "Drugą rzeczą, jaką zrobiliśmy jest połączenie kolumn **title** i **text** w jedną, a następnie wyczyszczenie powstałego tekstu poprzez usunięcie:\n",
    "- wielkich liter\n",
    "- interpunkcji\n",
    "- liczb\n",
    "- pojedynczych znaków\n",
    "- stopwordów (czyli wyrazów takich jak an, a, the, and itp)\n",
    "- przedrostków i przyrostków (stemizacja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2990f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "# funkcja odpowiedzialna za czyszczenie pojedynczego wiersza\n",
    "\n",
    "def clean_text(text, punctuation_chars):\n",
    "    text = text.lower()\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', ''.join(punctuation_chars)))\n",
    "    # remove digits\n",
    "    text = text.translate(str.maketrans('', '', string.digits))\n",
    "    # remove all single characters\n",
    "    pattern = r'(^| ).( |$)'\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    # remove multiple spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    # remove stopwords\n",
    "    text = delete_stopwords(text)\n",
    "    # stemming\n",
    "    text = stemming(text)\n",
    "    return text\n",
    "\n",
    "# funkcja odpowiedzialna za usuwanie stopwordów\n",
    "\n",
    "def delete_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# funkcja odpowiedzialna za stemizację\n",
    "\n",
    "def stemming(text):\n",
    "    words = word_tokenize(text)\n",
    "    porter = PorterStemmer()\n",
    "    stem_words = [porter.stem(word) for word in words]\n",
    "    return ' '.join(stem_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757a9e7",
   "metadata": {},
   "source": [
    "W efekcie uzyskaliśmy taką postać danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b6623b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>Ground Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ann coulter make believ gay friend make racist...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add dirti money launder obama billion iran ran...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>republican obamacar repeal go get done washing...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump possibl daca deal say border wall would ...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trump administr forc peac jame pinkerton origi...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66771</th>\n",
       "      <td>burundi opposit platform boycott new round pea...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66772</th>\n",
       "      <td>hillari messag former miss univers call miss p...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66773</th>\n",
       "      <td>cop crash car run away cop arriv daili sheepl ...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66774</th>\n",
       "      <td>trump stole idea north korean propaganda parod...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66775</th>\n",
       "      <td>break hillari clinton state depart gave russia...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               full_text Ground Label\n",
       "0      ann coulter make believ gay friend make racist...         fake\n",
       "1      add dirti money launder obama billion iran ran...         fake\n",
       "2      republican obamacar repeal go get done washing...         true\n",
       "3      trump possibl daca deal say border wall would ...         true\n",
       "4      trump administr forc peac jame pinkerton origi...         fake\n",
       "...                                                  ...          ...\n",
       "66771  burundi opposit platform boycott new round pea...         true\n",
       "66772  hillari messag former miss univers call miss p...         fake\n",
       "66773  cop crash car run away cop arriv daili sheepl ...         fake\n",
       "66774  trump stole idea north korean propaganda parod...         fake\n",
       "66775  break hillari clinton state depart gave russia...         fake\n",
       "\n",
       "[66776 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('clean_data.csv')\n",
    "df2 = df[['full_text', 'Ground Label']]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b546caa2",
   "metadata": {},
   "source": [
    "Zobaczmy bliżej, jak wygląda przykładowy full_text w porównaniu do tego, co było na początku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "835c62bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It s hard to believe, but Donald Trump does have a sizable amount of supporters who agree with his ideas on immigration and guns. Unsurprisingly, one of those people is Ann Coulter. A racist in her own regard, she falls perfectly into Trump s fan base.After the shooting massacre at a gay nightclub in Orlando, Florida, Coulter tweeted out: To my gay friends: Please consider the possibility that Hillary s immigration policies might get you killed. See Trump s speech today. To my gay friends: Please consider the possibility that Hillary's immigration policies might get you killed. See Trump's speech today.  Ann Coulter (@AnnCoulter) June 13, 2016Okay, first, what gay person would be her friend? And before you get offended in any regard to that question (you know who you are) I m a lesbian and find Coulter repulsive on every level. Which leads to the bigger question  what person, in general, would be her friend?During his speech, Trump of course spent time doubling-down on his racist and Islamophobic remarks that Muslims should be banned from immigrating to the United States.Does Coulter (and Trump) not even recognize the fact that the shooter (whose name I ll never mention, because that s what he wanted) was actually born in the United States, and was able to access his arsenal of weaponry and ammunition because of Florida s, and the United States, lax gun laws? Just like almost every shooter before him, and the only way to truly combat this sort of issue is to try to prevent them from happening in the first place.You can t always change a mindset, but you sure as hell can try to prevent a potential terrorist from owning a gun.The thing is, this is just Ann Coulter being Ann Coulter. She s a bigot and she s proud to be a bigot, and she doesn t care if you think she s a bigot. She s an isolationist who seems to think white people should reign supreme.It s just amusing to think that she wants us to believe she has gay friends. If, however, she really does have gay friends, they should probably realize they re friends with a bigot.Featured Photo by Frederick M. Brown/Getty Images   Twitter\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40610689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ann coulter make believ gay friend make racist point tweet hard believ donald trump sizabl amount support agre idea immigr gun unsurprisingli one peopl ann coulter racist regard fall perfectli trump fan baseaft shoot massacr gay nightclub orlando florida coulter tweet gay friend pleas consid possibl hillari immigr polici might get kill see trump speech today gay friend pleas consid possibl hillari immigr polici might get kill see trump speech today ann coulter anncoult june okay first gay person would friend get offend regard question know lesbian find coulter repuls everi level lead bigger question person gener would frienddur speech trump cours spent time doublingdown racist islamophob remark muslim ban immigr unit statesdo coulter trump even recogn fact shooter whose name never mention want actual born unit state abl access arsen weaponri ammunit florida unit state lax gun law like almost everi shooter way truli combat sort issu tri prevent happen first placey alway chang mindset sure hell tri prevent potenti terrorist own gunth thing ann coulter ann coulter bigot proud bigot care think bigot isolationist seem think white peopl reign supremeit amus think want us believ gay friend howev realli gay friend probabl realiz friend bigotfeatur photo frederick browngetti imag twitter'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['full_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c23885",
   "metadata": {},
   "source": [
    "Następnie podzieliśmy zbiór danych na treningowe i testowe. Robimy to już po czyszczeniu tekstów, gdyż robienie tego razem nie wpływało na wynik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e60710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(df):\n",
    "    x = df['full_text']\n",
    "    y = df['Ground Label']\n",
    "\n",
    "    # splitting data into train and test sets (and then splitting train test into train and test for us)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                                        random_state=123,\n",
    "                                                        test_size=0.3,\n",
    "                                                        shuffle=True)\n",
    "    x_train_train, x_train_test, y_train_train, y_train_test = train_test_split(x_train, y_train,\n",
    "                                                                                random_state=123,\n",
    "                                                                                test_size=0.3,\n",
    "                                                                                shuffle=True)\n",
    "    return x_train_train, x_train_test, x_test, y_train_train, y_train_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa9a163",
   "metadata": {},
   "source": [
    "Na koniec przekształciliśmy naszą kolumnę z tekstem przy użyciu TF-IDF, czyli Term Frequency-Inverse Document Frequency. Ma to na celu przekształcenie naszych danych w dane numeryczne, abyśmy w kolejnym etapie byli w stanie przygotować model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b7ebdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(x_train_train, x_train_test, x_test):\n",
    "    tfidfvectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "    tfidf_train_train = tfidfvectorizer.fit_transform(x_train_train)\n",
    "    tfidf_train_test = tfidfvectorizer.transform(x_train_test)\n",
    "    tfidf_test = tfidfvectorizer.transform(x_test)\n",
    "    return tfidf_train_train, tfidf_train_test, tfidf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ad7676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 28628)\t0.035198335198265325\n",
      "  (0, 108630)\t0.05428777118207438\n",
      "  (0, 166632)\t0.022705542277684555\n",
      "  (0, 60470)\t0.03481588669784062\n",
      "  (0, 85799)\t0.032979096756262455\n",
      "  (0, 160744)\t0.0635480935883643\n",
      "  (0, 57626)\t0.03196559937771667\n",
      "  (0, 135023)\t0.06711695016675373\n",
      "  (0, 119455)\t0.03568232501669057\n",
      "  (0, 45987)\t0.07213574290869089\n",
      "  (0, 140883)\t0.034277694459140064\n",
      "  (0, 30379)\t0.03962275092864471\n",
      "  (0, 157407)\t0.08802594336151842\n",
      "  (0, 8452)\t0.02854628139148879\n",
      "  (0, 150883)\t0.030759466919202564\n",
      "  (0, 146043)\t0.056186449546128045\n",
      "  (0, 70721)\t0.04436949515098163\n",
      "  (0, 133566)\t0.04337403267948117\n",
      "  (0, 145943)\t0.060728083586618395\n",
      "  (0, 23657)\t0.05412518209399045\n",
      "  (0, 35261)\t0.035387715914827186\n",
      "  (0, 94639)\t0.025645401262050702\n",
      "  (0, 168886)\t0.19607660705230934\n",
      "  (0, 80640)\t0.19607660705230934\n",
      "  (0, 48466)\t0.04157334648006114\n",
      "  :\t:\n",
      "  (32719, 88314)\t0.03977518894866833\n",
      "  (32719, 99187)\t0.02558604868759703\n",
      "  (32719, 18800)\t0.03844388428135811\n",
      "  (32719, 124016)\t0.037357770258437215\n",
      "  (32719, 99099)\t0.06585170744888809\n",
      "  (32719, 26100)\t0.03368307096807729\n",
      "  (32719, 103429)\t0.037316820803081845\n",
      "  (32719, 21492)\t0.1619298651284303\n",
      "  (32719, 147634)\t0.07703872361965247\n",
      "  (32719, 38303)\t0.03674877406449926\n",
      "  (32719, 142113)\t0.01971276235097491\n",
      "  (32719, 152170)\t0.04918611541634089\n",
      "  (32719, 158840)\t0.04907296228660212\n",
      "  (32719, 140883)\t0.038168895820657654\n",
      "  (32719, 8452)\t0.031786853161834515\n",
      "  (32719, 150883)\t0.03425127934836788\n",
      "  (32719, 94639)\t0.02855666533281575\n",
      "  (32719, 142261)\t0.030733593376681016\n",
      "  (32719, 126141)\t0.043198498369377475\n",
      "  (32719, 118604)\t0.07747452766248063\n",
      "  (32719, 129496)\t0.033479538285327716\n",
      "  (32719, 134675)\t0.03941311622145992\n",
      "  (32719, 130515)\t0.016029543342818166\n",
      "  (32719, 151164)\t0.0640567267957988\n",
      "  (32719, 42848)\t0.02566887668305658\n"
     ]
    }
   ],
   "source": [
    "# Przykład dla zbioru danych treningowych\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "print(load_npz('train_data/x_train_train.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388ddf27",
   "metadata": {},
   "source": [
    "Pierwsza wartość w krotce oznacza numer wiersza, a druga token_id, czyli numer słowa. Wartości wygenerowane przez funkcję mówią nam o tym, jak bardzo wpływa ono na treść tekstu, na podstawie częstości pojawiania się w tekście i we wszystkich tekstach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
